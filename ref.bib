@article{q-learning-converge,
  author   = {Watkins, Christopher J. C. H.
              and Dayan, Peter},
  title    = {Q-learning},
  journal  = {Machine Learning},
  year     = {1992},
  month    = {May},
  day      = {01},
  volume   = {8},
  number   = {3},
  pages    = {279-292},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  issn     = {1573-0565},
  doi      = {10.1007/BF00992698},
  url      = {https://doi.org/10.1007/BF00992698}
}

@article{scheduling-optimal,
  title     = {The c$\mu$ rule revisited},
  volume    = {17},
  doi       = {10.2307/1427064},
  number    = {1},
  journal   = {Advances in Applied Probability},
  publisher = {Cambridge University Press},
  author    = {Buyukkoc, C. and Varaiya, P. and Walrand, J.},
  year      = {1985},
  pages     = {237–238}
}
